# 10. ì‹¤ì „ API í™œìš© ì˜ˆì œì™€ ë¶€íŠ¸ìº í”„ ì—°ê³„ ì‹¤ìŠµ

ğŸ“ ìœ„ì¹˜: /GenAI-Learning-Journey/ì„ íƒê³¼ì •_ìƒì„±í˜•AI/01_ChatGPT_basic/10_hands-on-api-practice.md  
ğŸ“… ì •ë¦¬ì¼: 2025-08-02  
ğŸ“š ì¶œì²˜: OpenAI API Documentation + ë¶€íŠ¸ìº í”„ ì‹¤ìŠµ ì»¤ë¦¬í˜ëŸ¼ ì—°ê³„

---

## ğŸ¯ í•™ìŠµ ëª©í‘œ

> OpenAI APIì˜ ì‹¤ì „ í™œìš©ë²•ì„ ë‹¨ê³„ë³„ ì˜ˆì œë¥¼ í†µí•´ í•™ìŠµí•˜ê³ ,  
> ë¶€íŠ¸ìº í”„ í”„ë¡œì íŠ¸ì— ì§ì ‘ ì ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ êµ¬í˜„ ëŠ¥ë ¥ì„ ìŠµë“í•œë‹¤.

---

## ğŸ›  ê°œë°œ í™˜ê²½ ì„¤ì •

### 1. ê°€ìƒí™˜ê²½ ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜

```
# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv genai_env

# í™œì„±í™”
# Windows:
genai_env\Scripts\activate
# macOS/Linux:
source genai_env/bin/activate

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install openai python-dotenv requests pandas streamlit
```

### 2. API í‚¤ ì„¤ì •

```
# .env íŒŒì¼ ìƒì„±
OPENAI_API_KEY=sk-proj-your-api-key-here

# Pythonì—ì„œ ì‚¬ìš©
import os
from dotenv import load_dotenv

load_dotenv()
api_key = os.getenv('OPENAI_API_KEY')
```

### 3. ê¸°ë³¸ í´ë¼ì´ì–¸íŠ¸ ì„¤ì •

```
from openai import OpenAI
import os

client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

# ì—°ê²° í…ŒìŠ¤íŠ¸
try:
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": "Hello!"}],
        max_tokens=10
    )
    print("âœ… API ì—°ê²° ì„±ê³µ!")
    print("ì‘ë‹µ:", response.choices.message.content)
except Exception as e:
    print("âŒ API ì—°ê²° ì‹¤íŒ¨:", str(e))
```

---

## ğŸ“š í•µì‹¬ í™œìš© íŒ¨í„´

### 1. ê¸°ë³¸ ëŒ€í™”í˜• AI

```
def basic_chat(user_input):
    """ê°„ë‹¨í•œ ì±„íŒ… í•¨ìˆ˜"""
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": user_input}
            ],
            max_tokens=200,
            temperature=0.7
        )
        
        return response.choices.message.content
    
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ì‚¬ìš© ì˜ˆì‹œ
user_question = "Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì€?"
answer = basic_chat(user_question)
print(f"ì§ˆë¬¸: {user_question}")
print(f"ë‹µë³€: {answer}")
```

### 2. í…ìŠ¤íŠ¸ ìš”ì•½ ì‹œìŠ¤í…œ

```
def summarize_text(text, summary_length="short"):
    """í…ìŠ¤íŠ¸ ìš”ì•½ í•¨ìˆ˜"""
    
    length_instructions = {
        "short": "3-5ì¤„ë¡œ ê°„ë‹¨íˆ",
        "medium": "í•œ ë¬¸ë‹¨(5-8ì¤„)ìœ¼ë¡œ", 
        "long": "2-3ë¬¸ë‹¨ìœ¼ë¡œ ìƒì„¸íˆ"
    }
    
    prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ {length_instructions.get(summary_length, "ê°„ë‹¨íˆ")} ìš”ì•½í•´ì£¼ì„¸ìš”:

ì›ë¬¸:
{text}

ìš”ì•½ ì‹œ ë‹¤ìŒì„ í¬í•¨í•´ì£¼ì„¸ìš”:
- í•µì‹¬ ì£¼ì œì™€ ë©”ì‹œì§€
- ì£¼ìš” ë°ì´í„°ë‚˜ ìˆ˜ì¹˜ (ìˆëŠ” ê²½ìš°)
- ê²°ë¡  ë˜ëŠ” ì‹œì‚¬ì 
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=300,
            temperature=0.3
        )
        
        return response.choices.message.content
    
    except Exception as e:
        return f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# ì‚¬ìš© ì˜ˆì‹œ
long_article = """
[ê¸´ ê¸°ì‚¬ë‚˜ ë¬¸ì„œ í…ìŠ¤íŠ¸]
"""

summary = summarize_text(long_article, "medium")
print("ğŸ“„ ìš”ì•½ ê²°ê³¼:")
print(summary)
```

### 3. ê°ì • ë¶„ì„ ë„êµ¬

```
def analyze_sentiment(text):
    """ê°ì • ë¶„ì„ í•¨ìˆ˜"""
    
    prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ê³  JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

í…ìŠ¤íŠ¸: "{text}"

ê²°ê³¼ í˜•ì‹:
{{
    "sentiment": "ê¸ì •/ë¶€ì •/ì¤‘ë¦½",
    "confidence": 0.85,
    "emotions": ["ê¸°ì¨", "ë§Œì¡±"],
    "keywords": ["ì¢‹ë‹¤", "ë§Œì¡±"],
    "explanation": "ë¶„ì„ ê·¼ê±° ì„¤ëª…"
}}
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=200,
            temperature=0.1
        )
        
        import json
        result = json.loads(response.choices.message.content)
        return result
    
    except Exception as e:
        return {"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}"}

# ì‚¬ìš© ì˜ˆì‹œ
reviews = [
    "ì´ ì œí’ˆ ì •ë§ ì¢‹ì•„ìš”! ì¶”ì²œí•©ë‹ˆë‹¤.",
    "ë°°ì†¡ì´ ë„ˆë¬´ ëŠ¦ì—ˆì–´ìš”. ì‹¤ë§ì…ë‹ˆë‹¤.",
    "ê·¸ëƒ¥ í‰ë²”í•œ ì œí’ˆì´ì—ìš”."
]

for review in reviews:
    result = analyze_sentiment(review)
    print(f"ë¦¬ë·°: {review}")
    print(f"ê°ì •: {result.get('sentiment', 'N/A')}")
    print(f"ì‹ ë¢°ë„: {result.get('confidence', 'N/A')}")
    print("---")
```

### 4. ì½”ë“œ ìƒì„± ë° ì„¤ëª…

```
def generate_code(description, language="python"):
    """ì½”ë“œ ìƒì„± í•¨ìˆ˜"""
    
    prompt = f"""
ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” {language} ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

ìš”êµ¬ì‚¬í•­: {description}

ì œê³µí•´ì•¼ í•  ë‚´ìš©:
1. ì™„ì „íˆ ì‘ë™í•˜ëŠ” ì½”ë“œ
2. ì½”ë“œ ì„¤ëª… (ì£¼ì„ í¬í•¨)
3. ì‚¬ìš© ì˜ˆì‹œ
4. ì£¼ì˜ì‚¬í•­ (ìˆëŠ” ê²½ìš°)

ì½”ë“œëŠ” ì‹¤í–‰ ê°€ëŠ¥í•˜ê³  ì˜¤ë¥˜ê°€ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤.
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=800,
            temperature=0.2
        )
        
        return response.choices.message.content
    
    except Exception as e:
        return f"ì½”ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"

# ì‚¬ìš© ì˜ˆì‹œ
code_request = "ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë‰´ìŠ¤ ì œëª©ì„ í¬ë¡¤ë§í•˜ëŠ” í•¨ìˆ˜"
generated_code = generate_code(code_request)
print("ğŸ”§ ìƒì„±ëœ ì½”ë“œ:")
print(generated_code)
```

---

## ğŸš€ ë¶€íŠ¸ìº í”„ ì—°ê³„ í”„ë¡œì íŠ¸

### í”„ë¡œì íŠ¸ 1: ìŠ¤ë§ˆíŠ¸ ë¬¸ì„œ ìš”ì•½ê¸°

```
import streamlit as st
import os
from openai import OpenAI

def document_summarizer():
    """Streamlit ê¸°ë°˜ ë¬¸ì„œ ìš”ì•½ ì›¹ì•±"""
    
    st.title("ğŸ“„ ìŠ¤ë§ˆíŠ¸ ë¬¸ì„œ ìš”ì•½ê¸°")
    st.write("ê¸´ ë¬¸ì„œë¥¼ ì…ë ¥í•˜ë©´ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ë“œë¦½ë‹ˆë‹¤.")
    
    # ì‚¬ìš©ì ì…ë ¥
    document_text = st.text_area(
        "ë¬¸ì„œ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”:",
        height=300,
        placeholder="ìš”ì•½í•˜ê³  ì‹¶ì€ ë¬¸ì„œë‚˜ ê¸°ì‚¬ë¥¼ ì—¬ê¸°ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”..."
    )
    
    summary_type = st.selectbox(
        "ìš”ì•½ ê¸¸ì´ ì„ íƒ:",
        ["ì§§ê²Œ (3-5ì¤„)", "ë³´í†µ (1ë¬¸ë‹¨)", "ìƒì„¸íˆ (2-3ë¬¸ë‹¨)"]
    )
    
    if st.button("ğŸ“‹ ìš”ì•½í•˜ê¸°"):
        if document_text.strip():
            with st.spinner("ìš”ì•½ ì¤‘..."):
                summary = summarize_text(
                    document_text, 
                    "short" if "ì§§ê²Œ" in summary_type else
                    "medium" if "ë³´í†µ" in summary_type else "long"
                )
                
                st.subheader("âœ… ìš”ì•½ ê²°ê³¼")
                st.write(summary)
                
                # í† í° ì‚¬ìš©ëŸ‰ í‘œì‹œ (ì„ íƒì‚¬í•­)
                st.info(f"ì›ë¬¸ ê¸¸ì´: {len(document_text)} ë¬¸ì")
                
        else:
            st.warning("ë¬¸ì„œ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")

# ì‹¤í–‰: streamlit run app.py
```

### í”„ë¡œì íŠ¸ 2: ê³ ê° ë¦¬ë·° ë¶„ì„ ëŒ€ì‹œë³´ë“œ

```
import pandas as pd
import streamlit as st
import plotly.express as px

def review_analyzer():
    """ê³ ê° ë¦¬ë·° ë¶„ì„ ë„êµ¬"""
    
    st.title("ğŸ” ê³ ê° ë¦¬ë·° ê°ì • ë¶„ì„")
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader(
        "CSV íŒŒì¼ ì—…ë¡œë“œ (ë¦¬ë·° ë°ì´í„°)",
        type=['csv']
    )
    
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        st.write("ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
        st.dataframe(df.head())
        
        # ë¦¬ë·° ì»¬ëŸ¼ ì„ íƒ
        review_column = st.selectbox(
            "ë¦¬ë·°ê°€ í¬í•¨ëœ ì»¬ëŸ¼ì„ ì„ íƒí•˜ì„¸ìš”:",
            df.columns.tolist()
        )
        
        if st.button("ğŸš€ ê°ì • ë¶„ì„ ì‹œì‘"):
            results = []
            progress_bar = st.progress(0)
            
            for idx, review in enumerate(df[review_column].dropna()):
                # ê°ì • ë¶„ì„ ìˆ˜í–‰
                sentiment_result = analyze_sentiment(str(review))
                results.append({
                    'review': review,
                    'sentiment': sentiment_result.get('sentiment', 'ì¤‘ë¦½'),
                    'confidence': sentiment_result.get('confidence', 0.5)
                })
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                progress_bar.progress((idx + 1) / len(df))
            
            # ê²°ê³¼ ì‹œê°í™”
            results_df = pd.DataFrame(results)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ğŸ“Š ê°ì • ë¶„í¬")
                sentiment_counts = results_df['sentiment'].value_counts()
                fig = px.pie(
                    values=sentiment_counts.values,
                    names=sentiment_counts.index,
                    title="ê°ì •ë³„ ë¦¬ë·° ë¹„ìœ¨"
                )
                st.plotly_chart(fig)
            
            with col2:
                st.subheader("ğŸ“ˆ ì‹ ë¢°ë„ ë¶„í¬")
                fig2 = px.histogram(
                    results_df,
                    x='confidence',
                    title="ë¶„ì„ ì‹ ë¢°ë„ ë¶„í¬",
                    nbins=20
                )
                st.plotly_chart(fig2)
            
            # ìƒì„¸ ê²°ê³¼ í…Œì´ë¸”
            st.subheader("ğŸ“‹ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
            st.dataframe(results_df)
            
            # CSV ë‹¤ìš´ë¡œë“œ
            csv = results_df.to_csv(index=False)
            st.download_button(
                "ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                csv,
                "sentiment_analysis_results.csv",
                "text/csv"
            )
```

### í”„ë¡œì íŠ¸ 3: AI í•™ìŠµ ì–´ì‹œìŠ¤í„´íŠ¸

```
def ai_tutor():
    """AI í•™ìŠµ ë„ìš°ë¯¸"""
    
    st.title("ğŸ“ AI í•™ìŠµ ì–´ì‹œìŠ¤í„´íŠ¸")
    
    # í•™ìŠµ ëª¨ë“œ ì„ íƒ
    mode = st.selectbox(
        "í•™ìŠµ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        ["ì§ˆë¬¸ë‹µë³€", "ê°œë…ì„¤ëª…", "ë¬¸ì œìƒì„±", "ì½”ë“œë¦¬ë·°"]
    )
    
    if mode == "ì§ˆë¬¸ë‹µë³€":
        question = st.text_input("ê¶ê¸ˆí•œ ê²ƒì„ ì§ˆë¬¸í•˜ì„¸ìš”:")
        difficulty = st.selectbox("ë‚œì´ë„:", ["ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰"])
        
        if st.button("ğŸ’¡ ë‹µë³€ë°›ê¸°"):
            tutor_prompt = f"""
ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI íŠœí„°ì…ë‹ˆë‹¤. {difficulty} ìˆ˜ì¤€ì˜ í•™ìŠµìì—ê²Œ 
ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”:

ì§ˆë¬¸: {question}

ë‹µë³€ ê°€ì´ë“œë¼ì¸:
- ë‹¨ê³„ë³„ë¡œ ì„¤ëª…
- êµ¬ì²´ì ì¸ ì˜ˆì‹œ í¬í•¨
- ê´€ë ¨ ê°œë… ê°„ë‹¨íˆ ì–¸ê¸‰
- ì¶”ê°€ í•™ìŠµ ë°©í–¥ ì œì‹œ
"""
            
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": tutor_prompt}],
                max_tokens=500,
                temperature=0.7
            )
            
            st.write("ğŸ“– **AI íŠœí„°ì˜ ì„¤ëª…:**")
            st.write(response.choices.message.content)
    
    elif mode == "ê°œë…ì„¤ëª…":
        concept = st.text_input("ì„¤ëª…ë°›ê³  ì‹¶ì€ ê°œë…:")
        
        if st.button("ğŸ“š ê°œë… í•™ìŠµ"):
            concept_prompt = f"""
ë‹¤ìŒ ê°œë…ì„ ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„¤ëª…í•´ì£¼ì„¸ìš”:

ê°œë…: {concept}

ì„¤ëª… êµ¬ì¡°:
1. ê°„ë‹¨í•œ ì •ì˜
2. ì™œ ì¤‘ìš”í•œì§€
3. ì‹¤ìƒí™œ ì˜ˆì‹œ
4. ê´€ë ¨ ê°œë…ë“¤
5. í•™ìŠµ íŒ
"""
            
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": concept_prompt}],
                max_tokens=600,
                temperature=0.6
            )
            
            st.write("ğŸ§  **ê°œë… ì„¤ëª…:**")
            st.write(response.choices.message.content)
    
    elif mode == "ë¬¸ì œìƒì„±":
        topic = st.text_input("ë¬¸ì œë¥¼ ë§Œë“¤ ì£¼ì œ:")
        problem_count = st.slider("ë¬¸ì œ ê°œìˆ˜:", 1, 5, 3)
        
        if st.button("ğŸ“ ë¬¸ì œ ìƒì„±"):
            problem_prompt = f"""
{topic} ì£¼ì œì— ëŒ€í•œ ì—°ìŠµë¬¸ì œ {problem_count}ê°œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ê° ë¬¸ì œëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ:
**ë¬¸ì œ X:**
[ë¬¸ì œ ë‚´ìš©]

**ì •ë‹µ:**
[ì •ë‹µê³¼ ê°„ë‹¨í•œ í•´ì„¤]

ë‚œì´ë„ëŠ” ì¤‘ê¸‰ ìˆ˜ì¤€ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
"""
            
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": problem_prompt}],
                max_tokens=800,
                temperature=0.8
            )
            
            st.write("ğŸ¯ **ìƒì„±ëœ ì—°ìŠµë¬¸ì œ:**")
            st.write(response.choices.message.content)
```

---

## ğŸ”§ ê³ ê¸‰ í™œìš© ê¸°ë²•

### 1. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬

```
def streaming_chat(user_input):
    """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ"""
    
    print("AI: ", end="", flush=True)
    
    try:
        stream = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": user_input}],
            max_tokens=200,
            temperature=0.7,
            stream=True  # ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
        )
        
        full_response = ""
        for chunk in stream:
            if chunk.choices.delta.content is not None:
                content = chunk.choices.delta.content
                print(content, end="", flush=True)
                full_response += content
        
        print()  # ì¤„ë°”ê¿ˆ
        return full_response
    
    except Exception as e:
        return f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜: {str(e)}"

# ì‚¬ìš© ì˜ˆì‹œ
user_question = "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."
streaming_chat(user_question)
```

### 2. ë°°ì¹˜ ì²˜ë¦¬

```
def batch_process_texts(texts, task_type="summarize"):
    """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ë°°ì¹˜ ì²˜ë¦¬"""
    
    results = []
    
    for i, text in enumerate(texts):
        print(f"ì²˜ë¦¬ ì¤‘... ({i+1}/{len(texts)})")
        
        if task_type == "summarize":
            result = summarize_text(text, "short")
        elif task_type == "sentiment":
            result = analyze_sentiment(text)
        else:
            result = "ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‘ì—… ìœ í˜•"
        
        results.append({
            'original': text[:100] + "..." if len(text) > 100 else text,
            'result': result,
            'index': i
        })
        
        # API í˜¸ì¶œ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
        import time
        time.sleep(1)
    
    return results

# ì‚¬ìš© ì˜ˆì‹œ
text_list = [
    "ì²« ë²ˆì§¸ ë¶„ì„í•  í…ìŠ¤íŠ¸...",
    "ë‘ ë²ˆì§¸ ë¶„ì„í•  í…ìŠ¤íŠ¸...",
    "ì„¸ ë²ˆì§¸ ë¶„ì„í•  í…ìŠ¤íŠ¸..."
]

batch_results = batch_process_texts(text_list, "sentiment")
for result in batch_results:
    print(f"ì›ë¬¸: {result['original']}")
    print(f"ê²°ê³¼: {result['result']}")
    print("---")
```

### 3. ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì¬ì‹œë„

```
import time
import random

def robust_api_call(prompt, max_retries=3):
    """ê²¬ê³ í•œ API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=200,
                temperature=0.7
            )
            
            return {
                "success": True,
                "content": response.choices.message.content,
                "attempt": attempt + 1
            }
        
        except Exception as e:
            print(f"ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {str(e)}")
            
            if attempt < max_retries - 1:
                # ì§€ìˆ˜ ë°±ì˜¤í”„ ëŒ€ê¸°
                wait_time = (2 ** attempt) + random.uniform(0, 1)
                print(f"{wait_time:.1f}ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(wait_time)
            else:
                return {
                    "success": False,
                    "error": str(e),
                    "attempts": max_retries
                }

# ì‚¬ìš© ì˜ˆì‹œ
result = robust_api_call("ê°„ë‹¨í•œ í”„ë¡œê·¸ë˜ë° íŒì„ ì•Œë ¤ì£¼ì„¸ìš”.")
if result["success"]:
    print(f"âœ… ì„±ê³µ (ì‹œë„ {result['attempt']}íšŒ)")
    print(result["content"])
else:
    print(f"âŒ ì‹¤íŒ¨: {result['error']}")
```

---

## ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### 1. í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 

```
class TokenTracker:
    """í† í° ì‚¬ìš©ëŸ‰ ì¶”ì  í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.total_tokens = 0
        self.requests = 0
        self.cost_per_token = 0.002 / 1000  # GPT-3.5-turbo ê¸°ì¤€
    
    def track_request(self, response):
        """API ì‘ë‹µì—ì„œ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ"""
        if hasattr(response, 'usage'):
            tokens_used = response.usage.total_tokens
            self.total_tokens += tokens_used
            self.requests += 1
            
            print(f"ì´ë²ˆ ìš”ì²­ í† í°: {tokens_used}")
            print(f"ëˆ„ì  í† í°: {self.total_tokens}")
            print(f"ì˜ˆìƒ ë¹„ìš©: ${self.total_tokens * self.cost_per_token:.4f}")
    
    def get_stats(self):
        """ì‚¬ìš© í†µê³„ ë°˜í™˜"""
        return {
            "total_requests": self.requests,
            "total_tokens": self.total_tokens,
            "average_tokens": self.total_tokens / max(self.requests, 1),
            "estimated_cost": self.total_tokens * self.cost_per_token
        }

# ì‚¬ìš© ì˜ˆì‹œ
tracker = TokenTracker()

response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[{"role": "user", "content": "Hello!"}],
    max_tokens=50
)

tracker.track_request(response)
print("í˜„ì¬ í†µê³„:", tracker.get_stats())
```

---

## ğŸ¯ ë¶€íŠ¸ìº í”„ ìµœì¢… í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´

### 1. í†µí•© AI ì—…ë¬´ ë„ìš°ë¯¸
- ë¬¸ì„œ ìš”ì•½, ê°ì • ë¶„ì„, ì½”ë“œ ìƒì„±ì„ í•˜ë‚˜ì˜ ì•±ì— í†µí•©
- Streamlit ëŒ€ì‹œë³´ë“œë¡œ êµ¬í˜„
- CSV/PDF íŒŒì¼ ì—…ë¡œë“œ ì§€ì›

### 2. ìŠ¤ë§ˆíŠ¸ ê³ ê° ì„œë¹„ìŠ¤ ë´‡
- FAQ ìë™ ì‘ë‹µ
- ê°ì • ë¶„ì„ ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ë¶„ë¥˜
- ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ í¬í•¨

### 3. êµìœ¡ìš© AI í”Œë«í¼
- ê°œì¸í™”ëœ í•™ìŠµ ê²½ë¡œ ì¶”ì²œ
- ìë™ ë¬¸ì œ ìƒì„± ë° ì±„ì 
- í•™ìŠµ ì§„ë„ ì¶”ì 

### 4. ì½˜í…ì¸  ìë™ ìƒì„± ë„êµ¬
- ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„±
- ì†Œì…œë¯¸ë””ì–´ ì¹´í”¼ ì‘ì„±
- SEO í‚¤ì›Œë“œ ë¶„ì„ ì—°ë™

---

## ğŸ’¡ ì‹¤ì „ íŒ ë° ì£¼ì˜ì‚¬í•­

### Do's (ê¶Œì¥ì‚¬í•­)
```
âœ… API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ì•ˆì „í•˜ê²Œ ê´€ë¦¬
âœ… ì ì ˆí•œ ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì‚¬ìš©ì í”¼ë“œë°±
âœ… í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ë¹„ìš© ê´€ë¦¬
âœ… í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬ ë° A/B í…ŒìŠ¤íŠ¸
âœ… ì‚¬ìš©ì ì…ë ¥ ê²€ì¦ ë° ë³´ì•ˆ ê³ ë ¤
```

### Don'ts (ì£¼ì˜ì‚¬í•­)
```
âŒ API í‚¤ë¥¼ ì½”ë“œì— í•˜ë“œì½”ë”©í•˜ì§€ ë§ ê²ƒ
âŒ ê³¼ë„í•œ API í˜¸ì¶œë¡œ ë¹„ìš© í­ë°œ ë°©ì§€
âŒ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ë¬´ë¶„ë³„í•˜ê²Œ APIì— ì „ì†¡ ê¸ˆì§€
âŒ ì‘ë‹µ ê²°ê³¼ë¥¼ ê²€ì¦ ì—†ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê¸ˆì§€
âŒ ì—ëŸ¬ ì²˜ë¦¬ ì—†ì´ í”„ë¡œë•ì…˜ ë°°í¬ ê¸ˆì§€
```

### ë¹„ìš© ì ˆì•½ íŒ
```
ğŸ’° ë¹„ìš© ìµœì í™” ì „ëµ:
- GPT-3.5-turboë¥¼ ê¸°ë³¸ìœ¼ë¡œ, í•„ìš”ì‹œì—ë§Œ GPT-4 ì‚¬ìš©
- max_tokens ì„¤ì •ìœ¼ë¡œ ë¶ˆí•„ìš”í•œ í† í° ì‚¬ìš© ë°©ì§€
- ë°°ì¹˜ ì²˜ë¦¬ë¡œ API í˜¸ì¶œ íšŸìˆ˜ ìµœì†Œí™”
- ìºì‹±ìœ¼ë¡œ ì¤‘ë³µ ìš”ì²­ ë°©ì§€
- í”„ë¡¬í”„íŠ¸ ìµœì í™”ë¡œ í† í° íš¨ìœ¨ì„± í–¥ìƒ
```

---

## ğŸ“‹ ì‹¤ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ê¸°ë³¸ ì„¤ì • í™•ì¸
- [ ] ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
- [ ] í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ
- [ ] API í‚¤ ì„¤ì • ë° ì—°ê²° í…ŒìŠ¤íŠ¸
- [ ] .env íŒŒì¼ .gitignoreì— ì¶”ê°€

### í•µì‹¬ ê¸°ëŠ¥ êµ¬í˜„
- [ ] ê¸°ë³¸ ì±„íŒ… ê¸°ëŠ¥ êµ¬í˜„
- [ ] í…ìŠ¤íŠ¸ ìš”ì•½ ê¸°ëŠ¥ êµ¬í˜„
- [ ] ê°ì • ë¶„ì„ ê¸°ëŠ¥ êµ¬í˜„
- [ ] ì˜¤ë¥˜ ì²˜ë¦¬ ë¡œì§ ì¶”ê°€

### ê³ ê¸‰ ê¸°ëŠ¥ ë„ì „
- [ ] ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ êµ¬í˜„
- [ ] ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•
- [ ] í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- [ ] Streamlit ì›¹ì•± ë°°í¬

### í”„ë¡œì íŠ¸ ì™„ì„±
- [ ] ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ê°œì„ 
- [ ] ì„±ëŠ¥ ìµœì í™” ì ìš©
- [ ] ë¬¸ì„œí™” ë° README ì‘ì„±
- [ ] í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‘ì„±

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- [01_openai-api-fundamentals.md](./01_openai-api-fundamentals.md) â€” API ê¸°ì´ˆ ê°œë…
- [02_prompt-engineering-principles.md](./02_prompt-engineering-principles.md) â€” í”„ë¡¬í”„íŠ¸ ì„¤ê³„
- [05_agent-workflow-design.md](./05_agent-workflow-design.md) â€” ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°
- [09_prompt-debugging-optimization.md](./09_prompt-debugging-optimization.md) â€” ì„±ëŠ¥ ìµœì í™”

---

## ğŸ“ í•™ìŠµ ë…¸íŠ¸

```
ğŸ’¡ ì˜¤ëŠ˜ì˜ í•µì‹¬ í¬ì¸íŠ¸:
1. ì‹¤ì „ í”„ë¡œì íŠ¸ëŠ” ê¸°ë³¸ API í˜¸ì¶œë¶€í„° ì‹œì‘í•´ì„œ ì ì§„ì  í™•ì¥
2. ì˜¤ë¥˜ ì²˜ë¦¬ì™€ ì‚¬ìš©ì ê²½í—˜ì„ ê³ ë ¤í•œ ê²¬ê³ í•œ ì‹œìŠ¤í…œ êµ¬ì¶•
3. í† í° ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ë¹„ìš© íš¨ìœ¨ì„± í™•ë³´
4. Streamlit ë“± ë„êµ¬ í™œìš©ìœ¼ë¡œ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… ê°œë°œ

ğŸ›  ì‹¤ì „ ì ìš© íŒ:
- ì‘ì€ ê¸°ëŠ¥ë¶€í„° ì™„ì„±í•˜ê³  ë‹¨ê³„ì ìœ¼ë¡œ í™•ì¥
- ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°˜ì˜í•œ ì§€ì†ì  ê°œì„ 
- ì½”ë“œ ì¬ì‚¬ìš©ì„±ì„ ê³ ë ¤í•œ ëª¨ë“ˆí™” ì„¤ê³„
- ë³´ì•ˆê³¼ ì„±ëŠ¥ì„ ëª¨ë‘ ê³ ë ¤í•œ ë°°í¬

ğŸš€ ë‹¤ìŒ ë‹¨ê³„ ë°œì „ ë°©í–¥:
- LangChain/LangGraphì™€ì˜ ì—°ë™
- ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í™œìš©í•œ RAG ì‹œìŠ¤í…œ
- ë©€í‹°ëª¨ë‹¬ AI í™œìš© (í…ìŠ¤íŠ¸+ì´ë¯¸ì§€)
- í´ë¼ìš°ë“œ ë°°í¬ ë° ìŠ¤ì¼€ì¼ë§ ì „ëµ
```

âœ… **01_ChatGPT_basic í´ë” ë¬¸ì„œ ì‹œë¦¬ì¦ˆ ì™„ì„±! ğŸ‰**  
**ì´ 10ê°œ ë¬¸ì„œë¡œ OpenAI API í™œìš©ì˜ Aë¶€í„° Zê¹Œì§€ ì²´ê³„ì ìœ¼ë¡œ ì™„ì£¼í–ˆìŠµë‹ˆë‹¤!**

